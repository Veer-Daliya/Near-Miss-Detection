<div align="center">

# Near-Miss Detection

### Real-Time Pedestrian-Vehicle Collision Risk Assessment

**A production-ready computer vision system for proactive traffic safety monitoring**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![YOLOv10](https://img.shields.io/badge/detection-YOLOv10-green.svg)](https://github.com/THU-MIG/yolov10)
[![ByteTrack](https://img.shields.io/badge/tracking-ByteTrack-orange.svg)](https://github.com/ifzhang/ByteTrack)
[![License: MIT](https://img.shields.io/badge/license-MIT-purple.svg)](LICENSE)

[Paper](#research-paper) | [Presentation](#presentation) | [Getting Started](#getting-started) | [Documentation](#documentation)

</div>

---

## Overview

**Near-Miss Detection** is an end-to-end computer vision pipeline that detects pedestrian-vehicle collision risks in real-time from traffic camera feeds. The system provides **1.5â€“3 seconds of advance warning** before potential collisions, enabling proactive safety interventions.

<div align="center">

| Feature | Performance |
|:-------:|:-----------:|
| Detection Accuracy | **94.2%** mAP@0.5 |
| Tracking Stability | **<5%** ID switches |
| Risk Detection F1 | **89%** on critical events |
| Real-Time Speed | **10+ FPS** on RTX 3080 |
| LPR Accuracy | **89.7%** with multi-frame aggregation |

</div>

### Key Capabilities

- **Collision Risk Prediction** â€” Physics-based Closest Point of Approach (CPA) analysis predicts time-to-contact and minimum separation distance
- **Calibration-Free Deployment** â€” Novel 3-method ground plane estimation cascade works without camera calibration
- **License Plate Recognition** â€” Multi-frame OCR aggregation achieves 90% accuracy for vehicle identification
- **Real-Time Performance** â€” GPU-accelerated pipeline runs at 10+ FPS on consumer hardware
- **PTZ Camera Support** â€” Handles pan-tilt-zoom cameras with automatic motion detection and tracker reset

---

## Research Paper

<div align="center">

<a href="https://github.com/InspiritAI/Near-Miss-Detection/raw/main/docs/paper/near_miss_detection.pdf">
<img src="assets/paper_thumbnail.svg" alt="Research Paper" width="300"/>
</a>

**[Download Paper (PDF)](https://github.com/InspiritAI/Near-Miss-Detection/raw/main/docs/paper/near_miss_detection.pdf)**

*Real-Time Pedestrian-Vehicle Collision Risk Assessment Using Physics-Based Trajectory Analysis and Multi-Modal Computer Vision*

</div>

The paper presents our complete methodology including:
- Multi-method ground plane estimation cascade
- Closest Point of Approach (CPA) algorithm adaptation
- Multi-frame OCR aggregation for license plate recognition
- Comprehensive experimental evaluation

---

## Presentation

<div align="center">

<a href="https://github.com/InspiritAI/Near-Miss-Detection/raw/main/docs/presentation/near_miss_presentation.pdf">
<img src="assets/presentation_thumbnail.svg" alt="Presentation" width="300"/>
</a>

**[Download Presentation (PDF)](https://github.com/InspiritAI/Near-Miss-Detection/raw/main/docs/presentation/near_miss_presentation.pdf)**

*15-minute technical presentation with speaker notes*

</div>

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VIDEO INPUT                                     â”‚
â”‚                     (RTSP / File / Webcam)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DETECTION                      â”‚  TRACKING                                  â”‚
â”‚  YOLOv10 (94% mAP)             â”‚  ByteTrack (<5% ID switch)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GROUND PLANE ESTIMATION                                                     â”‚
â”‚  Cascade: Lane-Based â†’ Horizon-Based â†’ Size-Based (100% coverage)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COLLISION PREDICTION           â”‚  LICENSE PLATE RECOGNITION                 â”‚
â”‚  CPA Algorithm (1.5-3s warning) â”‚  Multi-Frame Aggregation (90% accuracy)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT: Risk Alerts â€¢ Annotated Video â€¢ JSON Events â€¢ Evidence Frames      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Getting Started

### Prerequisites

- Python 3.9+
- CUDA-capable GPU (recommended) or Apple Silicon
- FFmpeg (for video decoding)

### Installation

```bash
# Clone the repository
git clone https://github.com/InspiritAI/Near-Miss-Detection.git
cd Near-Miss-Detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install paddlepaddle paddleocr lap
```

### Quick Start

```bash
# Basic detection with near-miss analysis
python scripts/run_detection.py --source video.mp4 --enable-near-miss

# Advanced usage with all features
python scripts/run_detection.py \
  --source traffic_video.mp4 \
  --model-size l \
  --confidence 0.4 \
  --fps 10 \
  --enable-near-miss \
  --plate-interval 1 \
  --output-dir ./results
```

### Output

The system generates:
- `annotated_output.mp4` â€” Video with bounding boxes, track IDs, and risk overlays
- `detections.json` â€” Structured frame-by-frame detection results
- `near_miss_events.json` â€” Collision risk events with timestamps and evidence
- `ocr_bboxes.jsonl` â€” License plate recognition results

---

## Feature Status

| Feature | Status | Module |
|---------|--------|--------|
| Object Detection (YOLOv10) | âœ… Implemented | `src/detect/` |
| Multi-Object Tracking (ByteTrack) | âœ… Implemented | `src/track/` |
| Pedestrian-in-Vehicle Filtering | âœ… Implemented | `src/filter/` |
| Ground Plane Estimation | âœ… Implemented | `src/ground_plane/` |
| Near-Miss Detection (CPA) | âœ… Implemented | `src/risk/` |
| Trajectory Tracking | âœ… Implemented | `src/risk/trajectory.py` |
| Collision Prediction | âœ… Implemented | `src/risk/collision_predictor.py` |
| License Plate Detection | âœ… Implemented | `src/lpr/plate_detector.py` |
| License Plate OCR | âœ… Implemented | `src/lpr/ocr.py` |
| Multi-Frame Plate Aggregation | âœ… Implemented | `src/lpr/aggregator.py` |
| Impact Detection | ğŸš§ Planned | â€” |
| VLM Escalation | ğŸš§ Planned | â€” |

---

## Key Innovations

### 1. Ground Plane Estimation Cascade

Our novel 3-method cascade enables metric-space prediction without camera calibration:

| Method | Success Rate | Mean Error | When Used |
|--------|-------------|------------|-----------|
| Lane-Based | 62% | 0.8m | Lane markings visible |
| Horizon-Based | 78% | 1.2m | Clear horizon line |
| Size-Based | 100% | 2.1m | Universal fallback |
| **Cascade (Ours)** | **100%** | **1.1m** | Automatic selection |

### 2. Physics-Based Collision Prediction

The Closest Point of Approach (CPA) algorithm provides interpretable, real-time predictions:

```
Time to Closest Approach:  t_CPA = -(r Â· w) / |w|Â²
Minimum Separation:        d_min = |r + t_CPA Â· w|

where r = relative position, w = relative velocity
```

**Risk Classification:**
| Risk Level | TTC | Min Distance |
|------------|-----|--------------|
| ğŸ”´ Critical | < 1.5s | < 2.0m |
| ğŸŸ¡ Warning | < 3.0s | < 3.0m |
| ğŸŸ¢ Safe | â‰¥ 3.0s | â‰¥ 3.0m |

### 3. Multi-Frame License Plate Aggregation

Confidence-weighted voting across frames improves OCR accuracy from 71% to 90%:

```
c*_i = argmax_c Î£_f w_f Â· ğŸ™[c_i,f = c]
```

Requires consensus across 3+ frames with confidence â‰¥ 0.8.

---

## Configuration

### Fixed Camera (`configs/fixed_camera.yaml`)

```yaml
camera:
  type: fixed
  source: "rtsp://192.168.1.100:554/stream1"
  fps: 10

detection:
  model: yolov10m
  confidence_threshold: 0.4
  classes: [person, car, truck, bus, motorcycle]

risk:
  horizon_frames: 30
  ttc_critical: 1.5
  ttc_warning: 3.0
  min_separation_critical: 2.0
  min_separation_warning: 3.0

lpr:
  enabled: true
  trigger_on: high_risk
  min_plate_confidence: 0.7
```

### PTZ Camera (`configs/ptz_camera.yaml`)

```yaml
camera:
  type: ptz
  source: "rtsp://192.168.1.101:554/stream1"

tracking:
  ptz_motion_threshold: 0.6
  ptz_reset_strategy: full

risk:
  use_homography: false  # Disable for unstable calibration
```

---

## Performance

| Component | Latency | Frequency |
|-----------|---------|-----------|
| Detection (YOLOv10) | 50â€“100ms | Every frame |
| Tracking (ByteTrack) | 20â€“30ms | Every frame |
| Risk Scoring (CPA) | 5â€“10ms | Every frame |
| Ground Plane | 30â€“50ms | Every 30 frames |
| LPR (detection + OCR) | 300â€“500ms | On-demand |

**Total Pipeline: 10+ FPS** on NVIDIA RTX 3080

---

## Project Structure

```
Near-Miss-Detection/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detect/          # YOLOv10 detection
â”‚   â”œâ”€â”€ track/           # ByteTrack tracking
â”‚   â”œâ”€â”€ filter/          # Spatial filtering (pedestrian-in-vehicle)
â”‚   â”œâ”€â”€ ground_plane/    # Ground plane estimation cascade
â”‚   â”œâ”€â”€ risk/            # Collision prediction (CPA)
â”‚   â”œâ”€â”€ lpr/             # License plate recognition
â”‚   â””â”€â”€ ingest/          # Video ingestion
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_detection.py # Main entry point
â”œâ”€â”€ configs/             # YAML configuration files
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ paper/           # LaTeX research paper
â”‚   â””â”€â”€ presentation/    # Beamer presentation + speaker script
â””â”€â”€ assets/              # Thumbnails and images
```

---

## Documentation

| Document | Description |
|----------|-------------|
| [Paper](docs/paper/near_miss_detection.tex) | Full research paper (LaTeX source) |
| [Presentation](docs/presentation/near_miss_presentation.tex) | Technical presentation (Beamer source) |
| [Speaker Script](docs/presentation/SPEAKER_SCRIPT.md) | Detailed presentation notes |

---

## Output Schema

### Risk Assessment

```json
{
  "frame_id": 1234,
  "timestamp": 1703678400.123,
  "risk_assessments": [
    {
      "pedestrian_track_id": 5,
      "vehicle_track_id": 12,
      "ttc_seconds": 1.8,
      "min_separation_meters": 1.2,
      "risk_level": "critical"
    }
  ]
}
```

### License Plate Result

```json
{
  "plate_text": "ABC1234",
  "plate_confidence": 0.94,
  "vehicle_track_id": 12,
  "evidence_frame_ids": [1458, 1460, 1465],
  "aggregation_method": "confidence_weighted_voting"
}
```

---

## Technologies

| Component | Technology |
|-----------|-----------|
| Object Detection | [YOLOv10](https://github.com/THU-MIG/yolov10) |
| Multi-Object Tracking | [ByteTrack](https://github.com/ifzhang/ByteTrack) |
| License Plate OCR | [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) |
| Video Processing | [OpenCV](https://opencv.org/) |
| Deep Learning | [PyTorch](https://pytorch.org/), [Ultralytics](https://ultralytics.com/) |

---

## Citation

If you use this work in your research, please cite:

```bibtex
@article{kent2024nearmiss,
  title={Real-Time Pedestrian-Vehicle Collision Risk Assessment Using
         Physics-Based Trajectory Analysis and Multi-Modal Computer Vision},
  author={Daliya, Veer},
  year={2024},
  institution={Inspirit AI}
}
```

---

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

<div align="center">

**Built with [Inspirit AI](https://www.inspiritai.com/)**

*Making roads safer through computer vision*

</div>
